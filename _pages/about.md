---
permalink: /
title: "Welcome to Fangxin Liu's Homepage~"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Fangxin (Leon) Liu is an Assistant Professor at Shanghai Jiao Tong University (SJTU), specializing in neural network acceleration (e.g., neural network compression and SW/HW co-design.), in-memory computing, and brain-inspired neuromorphic computing.

He obtained his Ph.D. Degree in Computer Science and Technology from Shanghai Jiao Tong University in 2023, under the supervision of Prof. Li Jiang. 
<!-- You can find more information about Prof. Jiang [here](https://cs.sjtu.edu.cn/~jiangli//). -->

The papers and related resources will be shared on my [Github](https://github.com/MXHX7199) in the near future.

News
-----------
`May/20/2024` Our "LowPASS" A ReRAM-based SNN Accelerator has been accepted by ISLPED 2024! Congratulations to Zongwu.

`Mar./20/2024` Our "UM-PIM" Data re-layouted machnism has been accepted by ISCA 2024! Congratulations to Yilong.

`Mar./18/2024` Fangxin Liu received 2023 Shanghai CCF Outstanding Dissertation Award.

`Feb./27/2024` Our 2 papers have been accepted by DAC 2024! Congratulations to Ning Yang.

`Dec./29/2023` The "SPARK" acceleration framework has been reported in [Jiqizhixin](https://mp.weixin.qq.com/s/SvLTyAyY8mZEmPL4OZ5Bcw)(机器之心).

`Nov./12/2023` Our paper "RTSA" has been accepted by DATE 2024! Congratulations to Jiahao.

`Oct./23/2023` Our paper "SPARK" has been accepted by HPCA 2024! Congratulations to Ning Yang.

`Sep./09/2023` Our 4 papers have been accepted by ASP-DAC 2023! Congratulations to Haomin, Shiyuan, Tian Li.

`Aug./25/2023` Our paper "PSQ" has been accepted by ICCD 2023! Congratulations to Ning Yang.

`Jul./21/2023` Our paper "HyperNode" has been accepted by ICCAD 2023! Congratulations to Haomin.

`Jul./18/2023` Our paper "ERA-BS" has been accepted by TC 2023!

`Feb./24/2023` Our paper "HyperAttack" has been accepted by DAC 2023! 

`Nov./18/2022` Our paper "SIMSnn" has been accepted by DATE 2023!

Research
-----------
Current research interests focuses on:

- Neural Network Acceleration (神经网络加速)
- In-memory Computing (存内计算)
- Brain-inspired Neuromorphic Computing (神经模态计算)


Recent Visits to this Site
-----------

<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=sNUIIgL1WU3gnVp7Lq7JpnhV-2YGPzHk9c4NSyeNuIc&co=4c98ce'></script>
