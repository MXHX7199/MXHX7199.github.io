---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---


You can also find my articles on <u><a href="https://scholar.google.com/citations?hl=zh-TW&user=dXzsaIsAAAAJ">my Google Scholar profile</a>.</u>

<font color=538F79>{=} denotes equal contribution; &emsp; {*} denotes corresponding author</font>



<!-- |  **HPCA 2024** <br> **(Top Conf. in Computer Architecture)** | <u><b>Fangxin Liu=</b></u>, Ning Yang=, Haomin Li, Zongwu Wang, Zhuoran Song, Songwen Pei, Li Jiang <br> <a href="#">SPARK: Scalable and Precision-Aware Acceleration of Neural  Networks via Efficient Encoding</a>  |
|  ----  | ----  |
| 单元格  | 单元格 |
| 单元格  | 单元格 |


<p align="left"><font size=13 style="background: #F7F7F7">**HPCA 2024** <br> **(Top Conf. in Computer Architecture)** <u><b>Fangxin Liu=</b></u>, Ning Yang=, Haomin Li, Zongwu Wang, Zhuoran Song, Songwen Pei, Li Jiang <br> <a href="#">SPARK: Scalable and Precision-Aware Acceleration of Neural  Networks via Efficient Encoding</a>  </font> </p>  -->

<!-- After joining SJTU. -->
<table width="100%" style="table-layout:auto;" style="font-size:inherit;" >
<tr ><td style="font-size:inherit;"><strong>DAC 2025</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;">  <u><b>Fangxin Liu=</b></u>,  Haomin Li=, Zongwu Wang, Bo Zhang, Mingzhe Zhang, Shoumeng Yan, and Li Jiang<br> <a href="#"> ALLMod: Exploring Area-Efficiency of LUT-based Large Number Modular Reduction via Hybrid Workloads</a>  <strong>(Acceptance Rate: 21%)</strong> 
</td></tr>

<tr ><td bgcolor="#F7F7F7"><strong>DAC 2024</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> Zongwu Wang=, Peng Xu=, <u><b>Fangxin Liu*</b></u>, Yiwei Hu, Qingxiao Sun, Gezi Li, Cheng Li, Xuan Wang, and Li Jiang <br> <a href="#"> MILLION: MasterIng Long-Context LLM InferenceVia Outlier-Immunized KV Product OuaNtization</a> <strong>(Acceptance Rate: 21%)</strong> 
</td></tr>

<tr ><td style="font-size:inherit;"><strong>DAC2025</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;"> <u><b>Fangxin Liu=,*</b></u>, Ning Yang=, Zongwu Wang, and Li Jiang <br> <a href="#"> BLOOM: Bit-Slice Framework for DNN Acceleration with Mixed-Precision</a>  <strong>(Acceptance Rate: 21%)</strong> 
</td></tr>

<tr ><td bgcolor="#F7F7F7"><strong>DAC 2024</strong><br>(Top Conf. in Design Automation)/td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> Ning Yang, Zongwu Wang, Qingxiao Sun, Liqiang Lu, Li Jiang, and <u><b>Fangxin Liu*</b></u> <br> <a href="#"> PISA:Efficient Precision-Slice Framework forLLMs with Adaptive Numerical Type</a>  <strong>(Acceptance Rate: 21%)</strong>  
</td></tr>

<tr ><td style="font-size:inherit;"><strong>DATE 2025</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;">  <u><b>Fangxin Liu=</b></u>, Haomin Li=, Zongwu Wang, Dongxu Lyu, and Li Jiang<br> <a href="#"> HyperDyn: Dynamic Dimensional Masking forEffcient Hyper-Dimensional Computing</a>  <strong>(Acceptance Rate: 21%)</strong> 
</td></tr>

<tr ><td bgcolor="#F7F7F7"><strong>DATE 2024</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> <u><b>Fangxin Liu=</b></u>, Haomin Li=, Zewen Sun, Zongwu Wang, and Li Jiang <br> <a href="#"> HyperNeO: Efficient and AccurateHyper-Dimensional Regression via Neural Optimization</a> <strong>(Acceptance Rate: 21%)</strong>  
</td></tr>

<tr ><td style="font-size:inherit;"><strong>DATE 2025</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;"> Haomin Li=, <u><b>Fangxin Liu=</b></u>, Zongwu Wang, Dongxu Lyu, Shiyuan Huang, Ning Yang, Qi Sun, Zhuoran Song, and Li Jiang<br> <a href="#"> TAIL: Exploiting Temporal Asynchronous Execution for Efficient Spiking Neural Networks with Inter-Layer Parallelism</a>  <strong>(Acceptance Rate: 21%)</strong> 
</td></tr>

<tr ><td bgcolor="#F7F7F7"><strong>DATE 2024</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> <u><b>Fangxin Liu=</b></u>, Ning Yang=, Zongwu Wang, Xuanpeng Zhu, Haidong Yao, Xiankui Xiong, Qi Sun, and Li Jiang <br> <a href="#"> OPS: Outlier-aware Precision-Slice Framework for LLM Acceleration</a>  <strong>(Acceptance Rate: 21%)</strong>  
</td></tr>

<tr ><td style="font-size:inherit;"><strong>DATE 2025</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;"> Zongwu Wang, <u><b>Fangxin Liu</b></u>, Peng Xu, Qingxiao Sun, Junping Zhao and Li Jiang <br> <a href="#">EVASION: Efficient KV Cache Compression via Product Quantization</a>  <strong>(Acceptance Rate: 21%)</strong> 
</td></tr>

<tr ><td bgcolor="#F7F7F7"><strong>HPCA 2025</strong><br>(Top Conf. in Computer Architecture)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> <u><b>Fangxin Liu=</b></u>, Shiyuan Huang=, Ning Yang, Zongwu Wang, Haomin Li, and Li Jiang <br> <a href="#"> CROSS: Compiler-Driven Optimization of Sparse DNNs Using  Sparse/Dense Computation Kernels</a> <strong>(Acceptance Rate: 21%)</strong> 
</td></tr>

<tr ><td style="font-size:inherit;"><strong>HPCA 2025</strong><br>(Top Conf. in Computer Architecture)</td><td style="font-size:inherit;"> Houshu he, Gang Li, <u><b>Fangxin Liu</b></u>, Li Jiang, Xiaoyang Liang, and Zhuoran Song <br> <a href="#"> GSArch: Breaking Memory Barriers in 3D Guassian  Splatting Training via Arcitectural Support</a>  <strong>(Acceptance Rate: 21%)</strong> 
</td></tr>

<tr ><td bgcolor="#F7F7F7"><strong>IEEE TCAS-AI 2024</strong><br>(Imp. Jour. in Design Automation)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> Ning Yang=, <u><b>Fangxin Liu=</b></u>, Zongwu Wang, Junping Zhao, Li Jiang <br> <a href="#"> SearchQ: Search-based Fine-Grained Quantization for Data-Free Model Compression</a> 
</td></tr>

<tr ><td style="font-size:inherit;"><strong>IEEE TODAES 2024</strong><br>(Imp. Jour. in Design Automation)</td><td style="font-size:inherit;"> Shiyuan Huang=, <u><b>Fangxin Liu=</b></u>, Tian Li, Zongwu Wang, Ning Yang, Haomin Li and Li Jiang <br> <a href="#"> STCO: Enhancing Training Efficiency via Structured Sparse Tensor Compilation Optimization</a>  <strong>(CCF Tier B)</strong>
</td></tr>

<tr ><td bgcolor="#F7F7F7"><strong>ASP-DAC 2025</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> <u><b>Fangxin Liu=</b></u>, Zongwu Wang=, Peng Xu, Shiyuan Huang and Li Jiang <br> <a href="#"> Exploiting Differential-Based Data Encoding for Enhanced Query Efficiency</a>  <strong>(Acceptance Rate: 28%)</strong>
</td></tr>

<tr ><td style="font-size:inherit;"><strong>ASP-DAC 2025</strong><br>(Top. Conf. in Design Automation)</td><td style="font-size:inherit;"> Haomin Li=, <u><b>Fangxin Liu=</b></u>, Zewen Sun, Zongwu Wang, Shiyuan Huang, Ning Yang, and Li Jiang <br> <a href="#"> NeuronQuant: Accurate and Efficient Post-Training Quantization for Spiking Neural Networks</a>  <strong>(Acceptance Rate: 28%)</strong>
</td></tr>

<tr ><td bgcolor="#F7F7F7"><strong>IEEE TCAD 2024</strong><br>(Top Journal in Computer-Aided Design)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> Shiyuan Huang, <u><b>Fangxin Liu*</b></u>, Tao Yang, Zongwu Wang Ning Yang, and Li Jiang <br> <a href="#"> SpMMPlu-Pro: An Enhanced Compiler Plug-In for Efficient SpMM and Sparsity Propagation Algorithm</a>  <strong>(CCF Tier A)</strong>
</td></tr>


<tr ><td style="font-size:inherit;"><strong>ICCD 2024</strong><br>(Import. Conf. in Computer Architecture)</td><td style="font-size:inherit;"> <u><b>Fangxin Liu=</b></u>, Ning Yang=, Zongwu Wang, Zhiyan Song, Tao Yang, and Li Jiang <br> <a href="#"> TBUS: Taming Bipartite Unstructured Sparsity for Energy-Effcient DNN Acceleration</a>  <strong>(Acceptance Rate: 25%)</strong>
</td></tr>

<tr ><td bgcolor="#F7F7F7"><strong>ICCD 2024</strong><br>(Import. Conf. in Computer Architecture)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> <u><b>Fangxin Liu=</b></u>, Ning Yang=,Zhiyan Song, Zongwu Wang and Li Jiang <br> <a href="#"> HOLES: Boosting Large Language Models Efficiency with Hardware-friendly Lossless Encoding</a>  <strong>(Acceptance Rate: 25%)</strong>
</td></tr>


<tr ><td style="font-size:inherit;"><strong>ICCD 2024</strong><br>(Import. Conf. in Computer Architecture)</td><td style="font-size:inherit;"> Zongwu Wang=, <u><b>Fangxin Liu=</b></u>, and Li Jiang <br> <a href="#"> PS4:A Low Power SNN Accelerator with Spike Speculative Scheme</a>  <strong>(Acceptance Rate: 25%)</strong>
</td></tr>


<tr ><td bgcolor="#F7F7F7"><strong>ICCD 2024</strong><br>(Import. Conf. in Computer Architecture)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> Longyu Zhao, Zongwu Wang, <u><b>Fangxin Liu*</b></u>, and Li Jiang <br> <a href="#"> Ninja: A Hardware Assisted System for Accelerating Nested Address Translation</a>  <strong>(Acceptance Rate: 25%)</strong>
</td></tr>


<tr ><td style="font-size:inherit;"><strong>MICRO 2024</strong><br>(Top Conf. in Computer Architecture)</td><td style="font-size:inherit;"> Zongwu Wang, <u><b>Fangxin Liu*</b></u>, Ning Yang, Shiyuan Huang, Haomin Li, and Li Jiang <br> <a href="#"> COMPASS: SRAM-Based Computing-in-Memory SNN Accelerator with  Adaptive Spike Speculation</a>  <strong>(Acceptance Rate: 22%)</strong>
</td></tr>


<tr ><td bgcolor="#F7F7F7"><strong>MICRO 2024</strong><br>(Top Conf. in Computer Architecture)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> Zhuoran Song, Houshu He,<u><b>Fangxin Liu*</b></u>, Yifan Hao, Xinkai Song, Li Jiang and Xiaoyao Liang <br> <a href="#"> SRender: Boosting Neural Radiance Field Efficiency via  Sensitivity-Aware Dynamic Precision Rendering</a>  <strong>(Acceptance Rate: 22%)</strong>
</td></tr>

<tr ><td style="font-size:inherit;"><strong>IEEE TPDS 2024</strong><br>(Top Journal in Computer Architecture)</td><td style="font-size:inherit;"> <u><b>Fangxin Liu</b></u>, Zongwu Wang, Wenbo Zhao, Ning Yang, Yongbiao Chen, Shiyuan Huang, Haomin Li, Tao Yang, Songwen Pei,Xiaoyao Liang,and Li Jiang <br> <a href="https://ieeexplore.ieee.org/document/10561563"> Exploiting Temporal-Unrolled Parallelism for Energy-Efficient SNN Acceleration</a>  <strong>(CCF Tier A)</strong>
</td></tr>


<tr ><td bgcolor="#F7F7F7"><strong>ISLPED 2024</strong><br>(Top Conf. in Low Power Design)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> Zongwu Wang, <u><b>Fangxin Liu*</b></u>, Longyu Zhao, Shiyuan Huang and Li Jiang <br> <a href="https://dl.acm.org/doi/pdf/10.1145/3665314.3672279"> LowPASS: A Low power PIM-based accelerator with Speculative Scheme for SNNs</a>  <strong>(Acceptance Rate: 21%)</strong>
</td></tr>

<tr ><td style="font-size:inherit;"><strong>ISCA 2024</strong><br>(Top Conf. in Computer Architecture)</td><td style="font-size:inherit;"> Yilong Zhao, Mingyu Gao, <u><b>Fangxin Liu*</b></u>, Yiwei Hu, Zongwu Wang, Han Lin, Ji Li, He Xian, Hanlin Dong, Tao Yang, Naifeng Jing, Xiaoyao Liang, Li Jiang <br> <a href="https://ieeexplore.ieee.org/abstract/document/10609641"> UM-PIM: DRAM-based PIM with Uniform & Shared Memory Space</a>  <strong>(Acceptance Rate: 18%)</strong>
</td></tr>


<tr ><td bgcolor="#F7F7F7"><strong>DAC 2024</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> <u><b>Fangxin Liu=</b></u>, Ning Yang=, Haomin Li, Zongwu Wang, Zhuoran Song, Songwen Pei, Li Jiang <br> <a href="#"> INSPIRE: Accelerating Deep Neural Networks via Hardware-friendly Index-Pair Encoding</a>  <strong>(Acceptance Rate: 23%)</strong>
</td></tr>

<tr ><td style="font-size:inherit;"><strong>DAC 2024</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;"> <u><b>Fangxin Liu=</b></u>, Ning Yang=, Haomin Li, Zongwu Wang, Zhuoran Song, Songwen Pei, Li Jiang <br> <a href="#">EOS: An Energy-Oriented Attack Framework for Spiking Neural Networks</a>  <strong>(Acceptance Rate: 23%)</strong>
</td></tr>

<tr ><td bgcolor="#F7F7F7"><strong>DATE 2024</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> Jiahao Sun, <u><b>Fangxin Liu=</b></u>, Yijian Zhang, Li Jiang and Rui Yang <br> <a href="https://ieeexplore.ieee.org/abstract/document/10546586">RTSA: An RRAM-TCAM based In-Memory-Search Accelerator for Sub-100 Î¼s Collision Detection</a>  <strong>(Acceptance Rate: 24%)</strong>
</td></tr>

<tr ><td style="font-size:inherit;"><strong>ASPLOS 2024</strong><br>(Top Conf. in Computer Architecture)</td><td style="font-size:inherit;"> Zhuoran Song, Chunyu Qi, <u><b>Fangxin Liu=</b></u>, Naifeng Jing, Xiaoyao Liang <br> <a href="https://dl.acm.org/doi/abs/10.1145/3620665.3640393">CMC: Video Transformer Acceleration via CODEC  Assisted Matrix Condensing</a>  <strong>(Acceptance Rate: 24%)</strong>
</td></tr>


<tr ><td bgcolor="#F7F7F7"><strong>HPCA 2024</strong><br>(Top Conf. in Computer Architecture)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> <u><b>Fangxin Liu=</b></u>, Ning Yang=, Haomin Li, Zongwu Wang, Zhuoran Song, Songwen Pei, Li Jiang <br> <a href="https://ieeexplore.ieee.org/abstract/document/10476472">SPARK: Scalable and Precision-Aware Acceleration of Neural  Networks via Efficient Encoding</a>  <strong>(Acceptance Rate: 18%)</strong>
</td></tr>

<tr ><td style="font-size:inherit;" ><strong>ASPDAC 2024</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;" > <u><b>Fangxin Liu=</b></u>, Haomin Li=, Ning Yang, Yichi Chen, Zongwu Wang, Tao Yang, Li Jiang <br> <a href="https://ieeexplore.ieee.org/abstract/document/10473823">PAAP-HD: PIM-Assisted Approximation for Efficient Hyper-Dimensional Computing</a> <strong>(Acceptance Rate: 29%)</strong>
</td></tr>

<tr ><td style="font-size:inherit;"  bgcolor="#F7F7F7"><strong>ASPDAC 2024</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> <u><b>Fangxin Liu=</b></u>, Haomin Li=, Ning Yang, Zongwu Wang, Tao Yang, Li Jiang <br> <a href="https://ieeexplore.ieee.org/document/10473984">TEAS: Exploiting Spiking Activity for Temporal-wise Adaptive Spiking Neural Networks</a>  <strong>(Acceptance Rate: 29%)</strong>
</td></tr>

<tr ><td style="font-size:inherit;" ><strong>ASPDAC 2024</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;" > Shiyuan Huang=, <u><b>Fangxin Liu=</b></u>, Tian Li, Zongwu Wang, Haomin Li, Li Jiang<br> <a href="https://ieeexplore.ieee.org/abstract/document/10473981">TSTC: Enabling Efficient Training via Structured Sparse Tensor Compilation</a>  <strong>(Acceptance Rate: 29%)</strong>
</td></tr>

<tr ><td style="font-size:inherit;"  bgcolor="#F7F7F7"><strong>ASPDAC 2024</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> Haomin Li=, <u><b>Fangxin Liu=</b></u>, Yichi Chen, Li Jiang<br> <a href="https://ieeexplore.ieee.org/abstract/document/10473907">HyperFeel: An Efficient Federated Learning Framework Using Hyperdimensional Computing</a>  <strong>(Acceptance Rate: 29%)</strong>
</td></tr>

<tr ><td style="font-size:inherit;"  ><strong>ICCD 2023</strong></td><td style="font-size:inherit;"  > <u><b>Fangxin Liu=</b></u>, Ning Yang=, Li Jiang<br> <a href="https://ieeexplore.ieee.org/abstract/document/10361000">PSQ: An Automatic Search Framework for Data-Free Quantization on PIM-based Architecture</a>  <strong>(Acceptance Rate: 28%)</strong>
</td></tr>

<tr ><td style="font-size:inherit;"  bgcolor="#F7F7F7"><strong>ICCAD 2023</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> Haomin Li=, <u><b>Fangxin Liu=</b></u>, Yichi Chen, Li Jiang<br> <a href="https://ieeexplore.ieee.org/abstract/document/10323813">HyperNode: An Efficient Node Classification Framework Using HyperDimensional Computing</a>  <strong>(Acceptance Rate: 23%)</strong>
</td></tr>


<tr ><td style="font-size:inherit;" ><strong>IEEE TC 2023</strong><br>(Top Journal in Computer Architecture)</td><td style="font-size:inherit;" > <u><b>Fangxin Liu</b></u>, Wenbo Zhao, Zongwu Wang, Yongbiao Chen, Xiaoyao Liang, Li Jiang<br> <a href="https://ieeexplore.ieee.org/document/10177200">ERA-BS: Boosting the Efficiency of ReRAM-based PIM Accelerator with Fine-Grained Bit-Level Sparsity</a>  <strong>(CCF Tier A)</strong>
</td></tr>


<tr ><td style="font-size:inherit;"  bgcolor="#F7F7F7"><strong>DAC 2024</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> <u><b>Fangxin Liu=</b></u>, Haomin Li=, Zongwu Wang, Yongbiao Chen, Li Jiang<br> <a href="https://ieeexplore.ieee.org/abstract/document/10247811">HyperAttack: An Efficient Attack Framework for HyperDimensional Computing</a>  <strong>(Acceptance Rate: 23%)</strong>
</td></tr>
<!-- </table> -->

<!-- During my Ph.D. -->
<!-- <table width="100%" style="table-layout:auto;" style="font-size:inherit;" > -->
<tr ><td style="font-size:inherit;" ><strong>ICCD 2022</strong></td><td style="font-size:inherit;" > <u><b>Fangxin Liu</b></u>, Zongwu Wang, Yongbiao Chen, Li Jiang<br> <a href="https://ieeexplore.ieee.org/abstract/document/9978437">Randomize and Match: Exploiting Irregular Sparsity for Energy Efficient Processing in SNNs</a>  <strong>(Acceptance Rate: 24%)</strong>
</td></tr>


<tr ><td style="font-size:inherit;"  bgcolor="#F7F7F7"><strong>IEEE TCAD 2022</strong><br>(Top Journal in Computer-Aided Design)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> <u><b>Fangxin Liu</b></u>, Zongwu Wang, Yongbiao Chen, Zhezhi He, Tao Yang, Xiaoyao Liang, Li Jiang<br> <a href="https://ieeexplore.ieee.org/document/9769275">SoBS-X: Squeeze-Out Bit Sparsity for ReRAM-Crossbar-Based Neural Network Accelerator</a>  <strong>(CCF Tier A)</strong>
</td></tr>


<tr ><td style="font-size:inherit;" ><strong>SIGIR 2022</strong><br>(Top Conf. in Information Retrieval)</td><td style="font-size:inherit;" > <u><b>Fangxin Liu</b></u>, Haomin Li, Xiaokang Yang, Li Jiang<br> <a href="https://dl.acm.org/doi/abs/10.1145/3477495.3531761">L3E-HD: A Framework Enabling Efficient Ensemble in High-Dimensional Space for Language Tasks</a>  <strong>(Acceptance Rate: 24%)</strong>
</td></tr>


<tr ><td style="font-size:inherit;"  bgcolor="#F7F7F7"><strong>IEEE TCAD 2022</strong><br>(Top Journal in Computer-Aided Design)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> <u><b>Fangxin Liu=</b></u>, Wenbo Zhao, Zongwu Wang, Yilong Zhao, Tao Yang, Yiran Chen, Li Jiang<br> <a href="https://ieeexplore.ieee.org/document/972425">IVQ: In-Memory Acceleration of DNN Inference Exploiting Varied Quantization</a>  <strong>(CCF Tier A)</strong>
</td></tr>

<tr ><td style="font-size:inherit;" ><strong>DAC 2022</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;" > <u><b>Fangxin Liu</b></u>, Wenbo Zhao, Zongwu Wang, Yongbiao Chen, Zhezhi He, Naifeng Jing, Xiaoyao Liang, Li Jiang<br> <a href="/files/%5BDAC-2022%5DEBSP_preprint.pdf">EBSP: Evolving Bit Sparsity Patterns for Hardware Friendly Inference of Quantized Deep Neural Networks</a>  <strong>(Acceptance Rate: 24.7%)</strong> 
</td></tr>


<tr ><td style="font-size:inherit;"  bgcolor="#F7F7F7"><strong>DAC 2022</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> <u><b>Fangxin Liu=</b></u>, Wenbo Zhao, Yongbiao Chen, Zongwu Wang, Zhezhi He, Rui Yang, Qidong Tang, Tao Yang, Cheng Zhuo<br> <a href="/files/%5BDAC-2022%5DPIM-DH_preprint.pdf">PIM-DH: ReRAM based Processing in Memory Architecture for Deep Hashing Acceleration</a> <strong>(Acceptance Rate: 24.7%)</strong> 
</td></tr>

<tr ><td style="font-size:inherit;" ><strong>DAC 2022</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;" > <u><b>Fangxin Liu</b></u>, Wenbo Zhao, Zongwu Wang, Yongbiao Chen, Tao Yang, Zhezhi He, Xiaokang Yang, Li Jiang<br> <a href="/files/%5BDAC-2022%5DSATO_preprint.pdf">SATO: Spiking Neural Network Acceleration via Temporal Oriented Dataflow and Architecture</a> <strong>(Acceptance Rate: 24.7%)</strong> 
</td></tr>


<tr ><td style="font-size:inherit;"  bgcolor="#F7F7F7"><strong>ICASSP 2022</strong><br>(Top Conf. in Signal Processing)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> <u><b>Fangxin Liu=</b></u>, Wenbo Zhao, Yongbiao Chen, Zongwu Wang, Fei Dai<br> <a href="/files/%5BICASSP-22%5DDynSNN_preprint.pdf">Dynsnn: A dynamic approach to reduce redundancy in spiking neural networks</a> <strong>(CCF Tier B)</strong> 
</td></tr>

<tr ><td style="font-size:inherit;" ><strong>AAAI'22 (Oral)</strong><br>(Top Conf. in Artificial Intelligence)</td><td style="font-size:inherit;" > <u><b>Fangxin Liu</b></u>, Wenbo Zhao*, Yongbiao Chen, Zongwu Wang, Li Jiang<br> <a href="https://ojs.aaai.org/index.php/AAAI/article/view/20061">SpikeConverter: An Efficient Conversion Framework Zipping the Gap between Artificial Neural Networks and Spiking Neural Networks</a> <strong>(Acceptance Rate: 15%)</strong> 
</td></tr>


<tr ><td style="font-size:inherit;"  bgcolor="#F7F7F7"><strong>Frontiers in Neuroscience, 2021</strong><br>(SCI Tier 2)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> <u><b>Fangxin Liu=</b></u>, Wenbo Zhao=, Yongbiao Chen, Zongwu Wang, Tao Yang, Li Jiang<br> <a href="https://www.frontiersin.org/articles/10.3389/fnins.2021.756876/full">SSTDP: Supervised Spike Timing Dependent Plasticity for Efficient Spiking Neural Network Training</a> <strong>(Impact Factor: 4.7)</strong> 
</td></tr>

<tr ><td style="font-size:inherit;" ><strong>ICCD 2021</strong></td><td style="font-size:inherit;" > <u><b>Fangxin Liu</b></u>, Wenbo Zhao, Zhezhi He, Zongwu Wang, Yilong Zhao, Tao Yang, Jingnai Feng, Xiaoyao Liang, Li Jiang<br> <a href="https://ieeexplore.ieee.org/document/9643646">SME: ReRAM-based Sparse-Multiplication-Engine to Squeeze-Out Bit Sparsity of Neural Network</a> <strong>(Acceptance Rate: 24.4%)</strong> 
</td></tr>


<tr ><td style="font-size:inherit;"  bgcolor="#F7F7F7"><strong>ICCV 2021</strong><br>(Top Conf. in Computer Vision)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> <u><b>Fangxin Liu=</b></u>, Wenbo Zhao, Zhezhi He, Yanzhi Wang, Zongwu Wang, Changzhi Dai, Xiaoyao Liang, Li Jiang<br> <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Improving_Neural_Network_Efficiency_via_Post-Training_Quantization_With_Adaptive_Floating-Point_ICCV_2021_paper.html">Improving Neural Network Efficiency via Post-training Quantization with Adaptive Floating-Point</a> <strong>(Acceptance Rate: 25.9%)</strong> 
</td></tr>

<tr ><td style="font-size:inherit;" ><strong>ICCAD 2021</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;" > <u><b>Fangxin Liu</b></u>, Wenbo Zhao, Zhezhi He, Zongwu Wang, Yilong Zhao, Yongbiao Chen, Li Jiang<br> <a href="https://ieeexplore.ieee.org/document/9643569">Bit-Transformer: Transforming Bit-level Sparsity into Higher Preformance in ReRAM-based Accelerator</a> <strong>(Acceptance Rate: 23.5%)</strong> 
</td></tr>


<tr ><td style="font-size:inherit;"  bgcolor="#F7F7F7"><strong>GLSVLSI 2021</strong></td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> <u><b>Fangxin Liu=</b></u>, Wenbo Zhao, Zongwu Wang, Tao Yang, Li Jiang<br> <a href="https://dl.acm.org/doi/abs/10.1145/3453688.3461491">IM3A: Boosting Deep Neural Network Efficiency via In-Memory Addressing-Assisted Acceleration</a> <strong>(Acceptance Rate: 24%)</strong> 
</td></tr>

<tr ><td style="font-size:inherit;" ><strong>ICMR 2022</strong></td><td style="font-size:inherit;" > Yongbiao Chen, <u><b>Fangxin Liu</b></u>, et al.<br> <a href="#">TransHash: Transformer-based Hamming Hashing for Efficient Image Retrieval</a>
</td></tr>


<tr ><td style="font-size:inherit;"  bgcolor="#F7F7F7"><strong>ICMR 2022</strong></td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> Yongbiao Chen, <u><b>Fangxin Liu</b></u>, et al.<br> <a href="#">Supervised Contrastive Vehicle Quantization for Efficient Vehicle Retrieval</a>
</td></tr>

<tr ><td style="font-size:inherit;" ><strong>DATE 2022</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;" > Zongwu Wang, <u><b>Fangxin Liu</b></u>, et al.<br> <a href="#">Self-Terminated Write of Multi-Level Cell ReRAM for Efficient Neuromorphic Computing</a> <strong>(Best Paper Award)</strong>
</td></tr>


<tr ><td style="font-size:inherit;"  bgcolor="#F7F7F7"><strong>DATE 2022</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> Tao Yang, <u><b>Fangxin Liu</b></u>, et al.<br> <a href="#">DTQAtten: Leveraging Dynamic Token-based Quantization for Efficient Attention Architecture</a> <strong>(Nominated for Best Paper)</strong>
</td></tr>

<tr ><td style="font-size:inherit;" ><strong>ASPDAC 2022</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;" > Qidong Tang, <u><b>Fangxin Liu</b></u>, et al.<br> <a href="#">HAWIS: Hardware-Aware Automated WIdth Search for Accurate, Energy-Efficient and Robust Binary Neural Network on ReRAM Dot-Product Engine</a>
</td></tr>


<tr ><td style="font-size:inherit;"  bgcolor="#F7F7F7"><strong>DAC 2022</strong><br>(Top Conf. in Design Automation)</td><td style="font-size:inherit;"  bgcolor="#F7F7F7"> Tao Yang, <u><b>Fangxin Liu</b></u>, et al.<br> <a href="#">PIMGCN: A ReRAM-based PIM Design for Graph Convolutional Network Acceleration</a>
</td></tr>
</table>

<!-- to appear in 30th IEEE International Symposium on High-Performance Computer Architecture ( <font color="#2a9d8f">HPCA'24 </font> ). **(Top Conference in Computer Architecture, Acceptance Rate: 18%).**  -->

<!-- --------
**Fangxin Liu**=, Haomin Li=, Ning Yang, Yichi Chen, Zongwu Wang, Tao Yang, Li Jiang, "PAAP-HD: PIM-Assisted Approximation for Efficient Hyper-Dimensional Computing." to appear in 29th Asia and South Pacific Design Automation Conference ( <font color="#2a9d8f">ASPDAC'23 </font> ). **(Top Conference in Design Automation, Acceptance Rate: 29%).** 

--------
**Fangxin Liu**=, Haomin Li=, Ning Yang, Zongwu Wang, Tao Yang, Li Jiang, "TEAS: Exploiting Spiking Activity for Temporal-wise Adaptive Spiking Neural Networks." to appear in 29th Asia and South Pacific Design Automation Conference ( <font color="#2a9d8f">ASPDAC'23 </font> ). **(Top Conference in Design Automation, Acceptance Rate: 29%).** 

--------
Shiyuan Huang=, **Fangxin Liu**=, Tian Li, Zongwu Wang, Haomin Li, Li Jiang, "TSTC: Enabling Efficient Training via Structured Sparse Tensor Compilation." to appear in 29th Asia and South Pacific Design Automation Conference ( <font color="#2a9d8f">ASPDAC'23 </font> ). **(Top Conference in Design Automation, Acceptance Rate: 29%).** 

--------
Haomin Li=, **Fangxin Liu**=, Yichi Chen, Li Jiang, "HyperFeel: An Efficient Federated Learning Framework Using Hyperdimensional Computing." to appear in 29th Asia and South Pacific Design Automation Conference ( <font color="#2a9d8f">ASPDAC'23 </font> ). **(Top Conference in Design Automation, Acceptance Rate: 29%).** 


--------
**Fangxin Liu**=, Ning Yang=, Li Jiang, "PSQ: An Automatic Search Framework for Data-Free Quantization on PIM-based Architecture." to appear in 40th IEEE International Conference on Computer Design ( <font color="#2a9d8f">ICCD'23 </font> ). **(Acceptance Rate: 28%).** 

--------

Haomin Li=, **Fangxin Liu**=, Yichi Li, Li Jiang, "HyperNode: An Efficient Node Classification Framework Using HyperDimensional Computing." to appear in 42th IEEE/ACM International Conference on Computer-Aided Design ( <font color="#2a9d8f">ICCAD'23 </font> ). **(Top Conference in Design Automation, Acceptance Rate: 23%).** 

--------
**Fangxin Liu**, Wenbo Zhao, Zongwu Wang, Yongbiao Chen, Xiaoyao Liang, Li Jiang, "ERA-BS: Boosting the Efficiency of ReRAM-based PIM Accelerator with Fine-Grained Bit-Level Sparsity." to appear in IEEE Transactions on Computers 2023 ( <font color="#2a9d8f">TC'2023</font>). **(Top Journal in Computer Architecture, CCF Tier A).** [Link](https://ieeexplore.ieee.org/document/10177200)


--------
**Fangxin Liu**=, Haomin Li=, Zongwu Wang, Yongbiao Chen, Li Jiang, "HyperAttack: An Efficient Attack Framework for HyperDimensional Computing ." to appear in 60th Design Automation Conference ( <font color="#2a9d8f">DAC'23</font>). **(Top Conference in Design Automation, Acceptance Rate: 23%).**

--------
**Fangxin Liu**, Zongwu Wang, Yongbiao Chen, Li Jiang, "Randomize and Match: Exploiting Irregular Sparsity for Energy Efficient Processing in SNNs ." to appear in 40th IEEE International Conference on Computer Design ( <font color="#2a9d8f">ICCD'22</font>). **(Acceptance Rate: 24%).**

--------
**Fangxin Liu**, Zongwu Wang, Yongbiao Chen, Zhezhi He, Tao Yang, Xiaoyao Liang, Li Jiang, "SoBS-X: Squeeze-Out Bit Sparsity for ReRAM-Crossbar-Based Neural Network Accelerator.", IEEE Transactions on Computer Aided Design of Integrated Circuits and Systems ( <font color="#2a9d8f">IEEE TCAD</font>), 2022. **(Top Journal in Computer-Aided Design, CCF Tier A).** [Link](https://ieeexplore.ieee.org/document/9769275)

--------
**Fangxin Liu**, Haomin Li, Xiaokang Yang, Li Jiang, "L3E-HD: A Framework Enabling Efficient Ensemble in High-Dimensional Space for Language Tasks." to appear in 45th International ACM SIGIR Conference on Research and Development in Information Retrieval ( <font color="#2a9d8f">SIGIR'22 </font> ). **(Top Conference in  Information Retrieval, Acceptance Rate: 24.7%).** [Code](https://github.com/MXHX7199/SIGIR22-EnsembleHDC) [Link](https://dl.acm.org/doi/abs/10.1145/3477495.3531761)

--------

**Fangxin Liu**, Wenbo Zhao, Zongwu Wang, Yilong Zhao, Tao Yang, Yiran Chen, Li Jiang,  "IVQ: In-Memory Acceleration of DNN Inference Exploiting Varied Quantization." to appear in IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems ( <font color="#2a9d8f"> IEEE TCAD </font> ). **(Top Journal in Computer-Aided Design, CCF Tier A).** [Link](https://ieeexplore.ieee.org/document/972425)

--------

**Fangxin Liu**, Wenbo Zhao, Zongwu Wang, Yongbiao Chen, Zhezhi He, Naifeng Jing, Xiaoyao Liang, Li Jiang, "EBSP: Evolving Bit Sparsity Patterns for Hardware Friendly Inference of Quantized Deep Neural Networks." to appear in 59th ACM/IEEE Design Automation Conference ( <font color="#2a9d8f"> DAC'22 </font> ). **(Top Conference in Design Automation, Acceptance Rate: 24.7%).** [Slides](/files/%5BDAC-2022%5DEBSP_slides.pdf) [Link](/files/%5BDAC-2022%5DEBSP_preprint.pdf)

--------

**Fangxin Liu**, Wenbo Zhao, Yongbiao Chen, Zongwu Wang, Zhezhi He, Rui Yang, Qidong Tang, Tao Yang, Cheng Zhuo, Li Jiang, "PIM-DH: ReRAM based Processing in Memory Architecture for Deep Hashing Acceleration." to appear in 59th ACM/IEEE Design Automation Conference ( <font color="#2a9d8f">DAC'22 </font> ). **(Top Conference in Design Automation, Acceptance Rate: 24.7%).** [Slides](/files/%5BDAC-2022%5DPIM-DH_slides.pdf) [Link](/files/%5BDAC-2022%5DPIM-DH_preprint.pdf)

--------

**Fangxin Liu**, Wenbo Zhao, Zongwu Wang, Yongbiao Chen, Tao Yang, Zhezhi He, Xiaokang Yang, Li Jiang, "SATO: Spiking Neural Network Acceleration via Temporal Oriented Dataflow and Architecture." to appear in 59th ACM/IEEE Design Automation Conference ( <font color="#2a9d8f">DAC'22 </font> ). **(Top Conference in Design Automation, Acceptance Rate: 24.7%).** [Slides](/files/%5BDAC-2022%5DSATO_slides.pdf) [Link](/files/%5BDAC-2022%5DSATO_preprint.pdf)

--------

**Fangxin Liu**, Wenbo Zhao, Yongbiao Chen, Zongwu Wang, Fei Dai,  "Dynsnn: A dynamic approach to reduce redundancy in spiking neural networks." to appear in 47th IEEE International Conference on Acoustics, Speech and Signal Processing ( <font color="#2a9d8f">ICASSP'22 </font> ). **(Top Conference in Signal Processing, CCF Tier B).** [Slides](/files/%5BICASSP-22%5DDynSNN_poster.pdf) [Link](/files/%5BICASSP-22%5DDynSNN_preprint.pdf)

--------

**Fangxin Liu**, Wenbo Zhao*, Yongbiao Chen, Zongwu Wang, Li Jiang, "SpikeConverter: An Efficient Conversion Framework Zipping the Gap between Artificial Neural Networks and Spiking Neural Networks." to appear in 36th AAAI Conference on Artificial Intelligence ( <font color="#2a9d8f">AAAI'22 (Oral)</font> ). **(Top Conference in Artificial Intelligence, Acceptance Rate: 15%).** [Poster](/files/%5BAAAI-22%5DSpikeConverter_poster.pdf) [Link](https://ojs.aaai.org/index.php/AAAI/article/view/20061) [News](href="https://mp.weixin.qq.com/s/OZ-dsdwqGqUJWUqQretclQ") [Talk](href="https://www.bilibili.com/video/BV1fr4y1s7dK")

--------

**Fangxin Liu**, Wenbo Zhao*, Yongbiao Chen, Zongwu Wang, Tao Yang, Li Jiang, "SSTDP: Supervised Spike Timing Dependent Plasticity for Efficient Spiking Neural Network Training." to appear in Frontiers in Neuroscience, 15 (2021)( <font color="#2a9d8f">SCI Tier 2</font> ). **(Impact Factor 4.2).** [Code](https://github.com/MXHX7199/SNN-SSTDP) [Link](https://www.frontiersin.org/articles/10.3389/fnins.2021.756876/full)

--------

**Fangxin Liu**, Wenbo Zhao, Zhezhi He, Zongwu Wang, Yilong Zhao, Tao Yang, Jingnai Feng, Xiaoyao Liang, Li Jiang, "SME: ReRAM-based Sparse-Multiplication-Engine to Squeeze-Out Bit Sparsity of Neural Network." to appear in 39th IEEE International Conference on Computer Design ( <font color="#2a9d8f">ICCD'21 </font> ). **(Acceptance Rate: 24.4%).** [Slides](/files/%5BICCD-21%5DSME_slides.pdf) [Link](https://ieeexplore.ieee.org/document/9643646)

--------

**Fangxin Liu**, Wenbo Zhao, Zhezhi He, Yanzhi Wang, Zongwu Wang, Changzhi Dai, Xiaoyao Liang, Li Jiang, "Improving Neural Network Efficiency via Post-training Quantization with Adaptive Floating-Point.." to appear in International Conference on Computer Vision 2021 ( <font color="#2a9d8f">ICCV'21 </font> ). **(Top Conference in  Computer Vision, Acceptance Rate: 25.9%).** [Poster](/files/%5BICCV-21%5DAFP_poster.pdf) [Link](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Improving_Neural_Network_Efficiency_via_Post-Training_Quantization_With_Adaptive_Floating-Point_ICCV_2021_paper.html)

--------

**Fangxin Liu**, Wenbo Zhao, Zhezhi He, Zongwu Wang, Yilong Zhao, Yongbiao Chen, Li Jiang,  "Bit-Transformer: Transforming Bit-level Sparsity into Higher Preformance in ReRAM-based Accelerator." to appear in 40th IEEE/ACM International Conference on Computer-Aided Design ( <font color="#2a9d8f">ICCAD'21 </font> ). **(Top Conference in Design Automation, Acceptance Rate: 23.5%).** [Slides](/files/%5BICCAD-21%5DBit-Transformer_preprint.pdf) [Link](https://ieeexplore.ieee.org/document/9643569)

--------

**Fangxin Liu**, Wenbo Zhao, Zongwu Wang, Tao Yang, Li Jiang, "IM3A: Boosting Deep Neural Network Efficiency via In-Memory Addressing-Assisted Acceleration." to appear in 31st Great Lakes Symposium on VLSI  ( <font color="#2a9d8f">GLSVLSI'21 </font> ). **(Acceptance Rate: 24%).** [Link](https://dl.acm.org/doi/abs/10.1145/3453688.3461491)

--------

Yongbiao Chen, **Fangxin Liu**, et al. "TransHash: Transformer-based Hamming Hashing for Efficient Image Retrieval." to appear in ACM International Conference on Multimedia Retrieval 2022( <font color="#2a9d8f">ICMR'22 </font> ). **(Acceptance Rate: 30%).** [Link](https://dl.acm.org/doi/abs/10.1145/3512527.3531405)

--------


Yongbiao Chen, **Fangxin Liu**, et al. "Supervised Contrastive Vehicle Quantization for Efficient Vehicle Retrieval.." to appear in ACM International Conference on Multimedia Retrieval 2022( <font color="#2a9d8f">ICMR'22 </font> ). **(Acceptance Rate: 30%).** [Link](https://dl.acm.org/doi/abs/10.1145/3512527.3531432)

--------


Zongwu Wang, **Fangxin Liu**, et al. "Self-Terminated Write of Multi-Level Cell ReRAM for Efficient Neuromorphic Computing." to appear in 25th Design, Automation and Test in Europe Conference ( <font color="#2a9d8f">DATE'22 </font> ). **(Best Paper Award)).** [Slides](/files/%5BDATE-22%5DSTW_slides.pdf) [Link](/files/%5BDATE-22%5DSTW_preprint.pdf)

--------


Tao Yang, **Fangxin Liu**, et al. "DTQAtten: Leveraging Dynamic Token-based Quantization for Efficient Attention Architecture." to appear in 25th Design, Automation and Test in Europe Conference ( <font color="#2a9d8f">DATE'22 </font> ). **(nominated for best paper award).** [Slides](/files/%5BDATE-22%5DDTQAtten_slides.pdf) [Link](/files/%5BDATE-22%5DDTQAtten_slides.pdf)

--------

Qidong Tang, **Fangxin Liu**, et al. "HAWIS: Hardware-Aware Automated WIdth Search for Accurate, Energy-Efficient and Robust Binary Neural Network on ReRAM Dot-Product Engine." to appear in 27th Asia and South Pacific Design Automation Conference ( <font color="#2a9d8f">ASP-DAC'22 </font> ). **(Acceptance Rate: 36.5%).** [Slides](/files/%5BASPDAC-22%5DHAWIS_slides.pdf) [Link](/files/%5BASPDAC-22%5DHAWIS_preprint.pdf)

--------

Tao Yang, **Fangxin Liu**, et al. "PIMGCN: A ReRAM-based PIM Design for Graph Convolutional Network Acceleration." to appear in Design Automation Conference ( <font color="#2a9d8f">DAC'21 </font> ). **(Acceptance Rate: 26.5%).**  [Link](https://ieeexplore.ieee.org/abstract/document/9586231)

--------
<!-- {% for post in site.publications reversed %}
  {% include archive-single.html %}
{% endfor %} -->
