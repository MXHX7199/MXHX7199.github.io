---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

You can also find my articles on <u><a href="https://scholar.google.com/citations?hl=zh-TW&user=dXzsaIsAAAAJ">my Google Scholar profile</a>.</u>

--------
**Fangxin Liu**, et al. "Randomize and Match: Exploiting Irregular Sparsity for Energy Efficient Processing in SNNs ." to appear in 40th IEEE International Conference on Computer Design (<font color="#green">ICCD'22</font>). **(Acceptance Rate: 24%).**

--------
**Fangxin Liu**, et al. "SoBS-X: Squeeze-Out Bit Sparsity for ReRAM-Crossbar-Based Neural Network Accelerator.", IEEE Transactions on Computer Aided Design of Integrated Circuits and Systems (<font color="#green">IEEE TCAD</font>), 2022. **(CCF Tier A).** [Link](https://ieeexplore.ieee.org/document/9769275)

--------
**Fangxin Liu**, et al. "L3E-HD: A Framework Enabling Efficient Ensemble in High-Dimensional Space for Language Tasks.", to appear in 45th International ACM SIGIR Conference on Research and Development in Information Retrieval <font color="#green">(SIGIR'22 ).</font> **(Acceptance Rate: 24.7%).** [Code](https://github.com/MXHX7199/SIGIR22-EnsembleHDC) [Link](https://dl.acm.org/doi/abs/10.1145/3477495.3531761)

--------

**Fangxin Liu**, et al. "IVQ: In-Memory Acceleration of DNN Inference Exploiting Varied Quantization.", to appear in IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems <font color="#green">(TCAD'22 ).</font> **(CCF Tier A).** [Link](https://ieeexplore.ieee.org/document/972425)

--------

**Fangxin Liu**, et al. "EBSP: Evolving Bit Sparsity Patterns for Hardware Friendly Inference of Quantized Deep Neural Networks.", to appear in 59th ACM/IEEE Design Automation Conference <font color="#green">(DAC'22 ).</font> **(Acceptance Rate: 24.7%).** [Slides](/files/%5BDAC-2022%5DEBSP_slides.pdf) [Link](/files/%5BDAC-2022%5DEBSP_preprint.pdf)

--------

**Fangxin Liu**, et al. "PIM-DH: ReRAM based Processing in Memory Architecture for Deep Hashing Acceleration.", to appear in 59th ACM/IEEE Design Automation Conference <font color="#green">(DAC'22 ).</font> **(Acceptance Rate: 24.7%).** [Slides](/files/%5BDAC-2022%5DPIM-DH_slides.pdf) [Link](/files/%5BDAC-2022%5DPIM-DH_preprint.pdf)

--------

**Fangxin Liu**, et al. "SATO: Spiking Neural Network Acceleration via Temporal Oriented Dataflow and Architecture.", to appear in 59th ACM/IEEE Design Automation Conference <font color="#green">(DAC'22 ).</font> **(Acceptance Rate: 24.7%).** [Slides](/files/%5BDAC-2022%5DSATO_slides.pdf) [Link](/files/%5BDAC-2022%5DSATO_preprint.pdf)

--------

**Fangxin Liu**, et al. "Dynsnn: A dynamic approach to reduce redundancy in spiking neural networks.", to appear in 47th IEEE International Conference on Acoustics, Speech and Signal Processing <font color="#green">(ICASSP'22 ).</font> **(CCF Tier B).** [Slides](/files/%5BICASSP-22%5DDynSNN_poster.pdf) [Link](/files/%ICASSP-22%DynSNN_preprint.pdf)

--------

**Fangxin Liu**, et al. "SpikSpikeConverter: An Efficient Conversion Framework Zipping the Gap between Artificial Neural Networks and Spiking Neural Networks.", to appear in 36th AAAI Conference on Artificial Intelligence <font color="#green">(AAAI'22 (Oral)).</font> **(Acceptance Rate: 15%).** [Code](/files/%AAAI-22%SpikeConverter_poster.pdf) [Link](https://www.aaai.org/AAAI22Papers/AAAI-364.LiuF.pdf)

--------

**Fangxin Liu**, et al. "SSTDP: Supervised Spike Timing Dependent Plasticity for Efficient Spiking Neural Network Training.", to appear in Frontiers in Neuroscience, 15 (2021)<font color="#green">(SCI Tier 2).</font> **(Impact Factor 4.2).** [Code](https://github.com/MXHX7199/SNN-SSTDP) [Link](https://www.frontiersin.org/articles/10.3389/fnins.2021.756876/full)

--------

**Fangxin Liu**, et al. "SME: ReRAM-based Sparse-Multiplication-Engine to Squeeze-Out Bit Sparsity of Neural Network.", to appear in 39th IEEE International Conference on Computer Design <font color="#green">(ICCD'21 ).</font> **(Acceptance Rate: 24.4%).** [Slides](/files/%ICCD-21%SME_slides.pdf) [Link](https://ieeexplore.ieee.org/document/9643646)

--------

**Fangxin Liu**, et al. "Improving Neural Network Efficiency via Post-training Quantization with Adaptive Floating-Point..", to appear in International Conference on Computer Vision 2021 <font color="#green">(ICCV'21 ).</font> **(Acceptance Rate: 25.9%).** [Poster](/files/%ICCV-21%AFP_poster.pdf) [Link](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Improving_Neural_Network_Efficiency_via_Post-Training_Quantization_With_Adaptive_Floating-Point_ICCV_2021_paper.html)

--------

**Fangxin Liu**, et al. "Bit-Transformer: Transforming Bit-level Sparsity into Higher Preformance in ReRAM-based Accelerator.", to appear in 40th IEEE/ACM International Conference on Computer-Aided Design <font color="#green">(ICCAD'21 ).</font> **(Acceptance Rate: 23.5%).** [Slides](/files/%ICCAD-21%Bit-Transformer_preprint.pdf") [Link](https://ieeexplore.ieee.org/document/9643569)

--------

**Fangxin Liu**, et al. "IM3A: Boosting Deep Neural Network Efficiency via In-Memory Addressing-Assisted Acceleration.", to appear in 31st Great Lakes Symposium on VLSI  <font color="#green">(GLSVLSI'21 ).</font> **(Acceptance Rate: 24%).** [Slides](/files/%ICCAD-21%Bit-Transformer_preprint.pdf") [Link](https://dl.acm.org/doi/abs/10.1145/3453688.3461491)

--------

**Fangxin Liu**, et al. "TransHash: Transformer-based Hamming Hashing for Efficient Image Retrieval.", to appear in ACM International Conference on Multimedia Retrieval 2022<font color="#green">(ICMR'22 ).</font> **(Acceptance Rate: 30%).** [Link](https://dl.acm.org/doi/abs/10.1145/3512527.3531405)

--------


**Fangxin Liu**, et al. "Supervised Contrastive Vehicle Quantization for Efficient Vehicle Retrieval..", to appear in ACM International Conference on Multimedia Retrieval 2022<font color="#green">(ICMR'22 ).</font> **(Acceptance Rate: 30%).** [Link](https://dl.acm.org/doi/abs/10.1145/3512527.3531432)

--------


**Fangxin Liu**, et al. "Self-Terminated Write of Multi-Level Cell ReRAM for Efficient Neuromorphic Computing.", to appear in 25th Design, Automation and Test in Europe Conference <font color="#green">(DATE'22< ).</font> **(Best Paper Award)).** [Slides](/files/%DATE-22%STW_slides.pdf") [Link](/files/%DATE-22%STW_preprint.pdf)

--------


**Fangxin Liu**, et al. "DTQAtten: Leveraging Dynamic Token-based Quantization for Efficient Attention Architecture.", to appear in 25th Design, Automation and Test in Europe Conference <font color="#green">(DATE'22 ).</font> **(nominated for best paper award).** [Slides](/files/%DATE-22%DTQAtten_slides.pdf") [Link](/files/%DATE-22%DTQAtten_preprint.pdf)

--------

**Fangxin Liu**, et al. "HAWIS: Hardware-Aware Automated WIdth Search for Accurate, Energy-Efficient and Robust Binary Neural Network on ReRAM Dot-Product Engine.", to appear in 27th Asia and South Pacific Design Automation Conference <font color="#green">(ASP-DAC'22 ).</font> **(Acceptance Rate: 36.5%).** [Slides](/files/%ASPDAC-22%HAWIS_slides.pdf") [Link](/files/%ASPDAC-22%HAWIS_preprint.pdf)

--------

**Fangxin Liu**, et al. "PIMGCN: A ReRAM-based PIM Design for Graph Convolutional Network Acceleration.", to appear in Design Automation Conference <font color="#green">(DAC'21 ).</font> **(Acceptance Rate: 26.5%).**  [Link](https://ieeexplore.ieee.org/abstract/document/9586231)

--------
<!-- {% for post in site.publications reversed %}
  {% include archive-single.html %}
{% endfor %} -->
